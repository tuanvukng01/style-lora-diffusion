# Style-Aware Image Generation with LoRA

### ğŸ“ Project Overview

**Style-Aware Image Generation with LoRA** explores lightweight fine-tuning of text-to-image models to better reflect artistic styles during image generation. Specifically, we fine-tune the text encoder of **Stable Diffusion v1.5** using **LoRA (Low-Rank Adaptation)** to better condition on artistic style prompts like _â€œin the style of Impressionismâ€_ or _â€œCubismâ€_.

The training is conducted on a curated subset of the **WikiArt dataset**, where each image is paired with a style-specific caption (e.g., _â€œA castle on a cliff during sunset, in the style of Surrealismâ€_). Only the text encoder is adapted using LoRA, allowing fast and efficient fine-tuning with reduced compute.

We evaluate performance using **CLIPScore**, and **LPIPS** across several artistic styles and visualize the outputs in a comparative grid. The model shows improved alignment to style prompts without degrading generation quality.

## ğŸ“Š Benchmark Results

[//]: # (| Model         | FID â†“   | CLIP â†‘  | LPIPS â†“ |)

[//]: # (|---------------|---------|---------|---------|)

[//]: # (| Base SD       | XX.XX   | 0.XXX   | 0.XXX   |)

[//]: # (| Ours &#40;LoRA&#41;   | XX.XX   | 0.XXX   | 0.XXX   |)

<div align="center">
  <img src="assets/benchmark_combined_table.png" width="100%">
</div>


## ğŸ“ Project Structure

```
.
â”œâ”€â”€ config.yaml                     
â”œâ”€â”€ evaluate.py                    
â”œâ”€â”€ train.py                      
â”œâ”€â”€ utils.py                      
â”œâ”€â”€ README.md                     
â”œâ”€â”€ requirements.txt              
â”œâ”€â”€ assets/                       
â”‚   â””â”€â”€ benchmark_combined_table_grid.png
â””â”€â”€ .gitignore                    
```

[//]: # ()
[//]: # (## âš™ï¸ Setup)

[//]: # ()
[//]: # (Install dependencies:)

[//]: # ()
[//]: # (```bash)

[//]: # (pip install -r requirements.txt)

[//]: # (```)

[//]: # ()
[//]: # (Set up your LoRA fine-tuned model and base model paths in `config.yaml`.)

[//]: # ()
[//]: # (## ğŸ§ª Evaluation)

[//]: # ()
[//]: # (Run the benchmark:)

[//]: # ()
[//]: # (```bash)

[//]: # (python evaluate.py)

[//]: # (```)

[//]: # ()
[//]: # (Generated comparison grids and metrics will be saved to your configured logging directory.)

## ğŸ§  Credits

- [CompVis/stable-diffusion](https://github.com/CompVis/stable-diffusion) â€” for the original Stable Diffusion model
- [HuggingFace PEFT](https://github.com/huggingface/peft) â€” for LoRA-based fine-tuning
- [Diffusers](https://github.com/huggingface/diffusers) â€” for model pipeline and inference
- [TorchMetrics](https://github.com/Lightning-AI/torchmetrics) â€” for FID and LPIPS computation
- [Transformers](https://github.com/huggingface/transformers) â€” for CLIP model and text-image evaluation
- [WikiArt dataset](https://www.wikiart.org/) â€” as the training and evaluation data source

## ğŸ“œ License

CreativeML Open RAIL-M License
